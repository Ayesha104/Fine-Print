{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT+Classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xRKVXN0_lkUj","colab_type":"code","outputId":"b2b7b945-2889-4024-a7cc-213bfda168be","executionInfo":{"status":"ok","timestamp":1575530996272,"user_tz":-300,"elapsed":3791,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yygjIpJDGZr8","colab_type":"code","colab":{}},"source":["import pandas as pd\n","data=pd.read_csv(\"/content/drive/My Drive/sep/access.csv\",delimiter=',')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QXwZ3_7JRAr","colab_type":"code","outputId":"0d6aca4b-6eaf-4e9f-99d7-24684e79a6b3","executionInfo":{"status":"ok","timestamp":1575530996783,"user_tz":-300,"elapsed":4280,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["l=data.label.values\n","\n","if l.any():\n","  print (\"A\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDGnboP50R9q","colab_type":"code","outputId":"fe9988e8-4266-4360-9bce-d653a0e82df9","executionInfo":{"status":"ok","timestamp":1575530996784,"user_tz":-300,"elapsed":4270,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from sklearn.model_selection import train_test_split\n","df,dtest=train_test_split(data,test_size=0.20,random_state=2018)\n","print (\"train: \" ,df.shape )\n","print (\"test: \",dtest.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train:  (3050, 4)\n","test:  (763, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hOZaT-ijllsv","colab_type":"code","outputId":"31b1596e-4ad8-4a4d-a96c-41639c327ada","executionInfo":{"status":"ok","timestamp":1575530996785,"user_tz":-300,"elapsed":4259,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LMA2Nh5tlrpj","colab_type":"code","outputId":"0f4bb1f5-b4ef-4f35-a4e8-47dcf519d5a3","executionInfo":{"status":"ok","timestamp":1575531001889,"user_tz":-300,"elapsed":9352,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":339}},"source":["!pip install pytorch-pretrained-bert pytorch-nlp"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.27)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.11.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.27)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->pytorch-pretrained-bert) (2.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.27->boto3->pytorch-pretrained-bert) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G402-oHZl1lM","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hunm6CDVl6nZ","colab_type":"code","outputId":"b6e00556-d2bf-4736-ccdc-0a65a85d4686","executionInfo":{"status":"ok","timestamp":1575531001894,"user_tz":-300,"elapsed":9336,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla K80'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"sNOY2VOuJi69","colab_type":"code","colab":{}},"source":["segment=df.segment_txt.values\n","segment=[\"[CLS]\" + sentence + \"[SEP]\" for sentence in segment ]\n","label=df.label.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grLGC9CtJ-0d","colab_type":"code","outputId":"85ec907a-2bf1-47cc-97d5-dd6c4895bfb2","executionInfo":{"status":"ok","timestamp":1575531006398,"user_tz":-300,"elapsed":13818,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in segment]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tokenize the first sentence:\n","['[', 'cl', '##s', ']', 'we', 'may', 'also', 'use', 'other', 'industry', 'standard', 'technologies', 'like', 'pixel', 'tags', 'and', 'web', 'beacon', '##s', 'to', 'track', 'your', 'use', 'of', 'our', 'website', 'pages', 'and', 'promotions', ',', 'or', 'we', 'may', 'allow', 'our', 'third', 'party', 'service', 'providers', 'to', 'use', 'these', 'devices', 'on', 'our', 'behalf', '.', 'pixel', 'tags', 'and', 'web', 'beacon', '##s', 'are', 'tiny', 'graphic', 'images', 'placed', 'on', 'certain', 'pages', 'on', 'our', 'website', ',', 'or', 'in', 'our', 'emails', 'that', 'allow', 'us', 'to', 'determine', 'whether', 'you', 'have', 'performed', 'a', 'specific', 'action', '.', 'when', 'you', 'access', 'these', 'pages', 'or', 'open', 'or', 'click', 'an', 'email', ',', 'pixel', 'tags', 'and', 'web', 'beacon', '##s', 'generate', 'a', 'non', '-', 'personally', 'identifiable', 'notice', 'of', 'that', 'action', '.', 'pixel', 'tags', 'allow', 'us', 'to', 'measure', 'and', 'improve', 'our', 'understanding', 'of', 'visitor', 'traffic', 'and', 'behavior', 'on', 'our', 'website', ',', 'as', 'well', 'as', 'give', 'us', 'a', 'way', 'to', 'measure', 'our', 'promotions', 'and', 'performance', '.', 'we', 'may', 'also', 'utilize', 'pixel', 'tags', 'and', 'web', 'beacon', '##s', 'provided', 'by', 'our', 'affiliates', 'and', '/', 'or', 'marketing', 'partners', 'for', 'the', 'same', 'purposes', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mhoffIbkKOS2","colab_type":"code","outputId":"3ffabbe5-432f-4a5e-f864-4c1a5447dffe","executionInfo":{"status":"ok","timestamp":1575531006399,"user_tz":-300,"elapsed":13808,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["segmentlength=[len(sent) for sent in tokenized_texts]\n","print (max(segmentlength))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["445\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JXqd8JTbKw2v","colab_type":"code","colab":{}},"source":["MAX_LEN=300"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5xU8W5AMSk2","colab_type":"code","colab":{}},"source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iszbr6CvMVxu","colab_type":"code","colab":{}},"source":["input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_R3RrUIVMadx","colab_type":"code","colab":{}},"source":["attention_masks = []\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDabkictMkry","colab_type":"code","colab":{}},"source":["\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, label, \n","                                                            random_state=2018, test_size=0.2)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2018, test_size=0.2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4q-SivolMpBU","colab_type":"code","colab":{}},"source":["train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZGp7TzPMwWR","colab_type":"code","colab":{}},"source":["batch_size=16\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUUOpUkqM1XN","colab_type":"code","outputId":"234d6017-59b6-4e63-eb8a-cef1043427b0","executionInfo":{"status":"ok","timestamp":1575531015701,"user_tz":-300,"elapsed":23040,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"h_qs0yz3M4bS","colab_type":"code","colab":{}},"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKumNwl1M-op","colab_type":"code","outputId":"9a37e312-9a91-4c18-a0ba-1b21c557d1fd","executionInfo":{"status":"ok","timestamp":1575531015704,"user_tz":-300,"elapsed":23021,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["optimizer = BertAdam(optimizer_grouped_parameters,\n","                     lr=2e-5,\n","                     warmup=.1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["t_total value of -1 results in schedule not being applied\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uailL_nENBDo","colab_type":"code","colab":{}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = label.flatten()\n","\n","    return np.sum(pred_flat==labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeBJqxcHNIqw","colab_type":"code","outputId":"004c309b-208c-4ae3-aa6c-f77acdbe39c5","executionInfo":{"status":"ok","timestamp":1575532215578,"user_tz":-300,"elapsed":22670,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["t = [] \n","\n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  \n","  \n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train()\n","  \n","  # Tracking variables\n","  tr_loss = 0\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    train_loss_set.append(loss.item())    \n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    \n","    \n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","    \n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  \n","  model.eval()\n","\n","  # Tracking variables \n","  eval_loss, eval_accuracy = 0.0, 0.0\n","  nb_eval_steps, nb_eval_examples = 0.0, 0.0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    \n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    \n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.22345649234317486\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  \"\"\"\n","Epoch:  25%|██▌       | 1/4 [04:59<14:59, 299.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.0\n","Train loss: 0.17400353740340743\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 2/4 [10:00<10:00, 300.03s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.0\n","Train loss: 0.1521944577495257\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  75%|███████▌  | 3/4 [15:00<04:59, 299.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.0\n","Train loss: 0.11488546367759019\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch: 100%|██████████| 4/4 [19:59<00:00, 299.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.0\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Gly83nJFNcVX","colab_type":"code","colab":{}},"source":["sentences = dtest.segment_txt.values\n","\n","# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n","sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n","labels = dtest.label.values\n","\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","\n","MAX_LEN = 300\n","\n","# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(labels)\n","  \n","batch_size = 32  \n","\n","\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm_G_deZ2Kbl","colab_type":"code","colab":{}},"source":["# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vj9OY9TJ47Xn","colab_type":"code","outputId":"3398f46c-dfd9-41f9-cae5-8df9a86a8bed","executionInfo":{"status":"ok","timestamp":1575532244982,"user_tz":-300,"elapsed":43,"user":{"displayName":"Tehreem Javed","photoUrl":"","userId":"00899439759445247029"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","from sklearn.metrics import classification_report\n","print (classification_report(flat_predictions,flat_true_labels))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.99      0.94       663\n","           1       0.76      0.28      0.41       100\n","\n","    accuracy                           0.89       763\n","   macro avg       0.83      0.63      0.68       763\n","weighted avg       0.88      0.89      0.87       763\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bX1xbhv99KMV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}